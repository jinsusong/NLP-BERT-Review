{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_CoQA Chatbot model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNqWvkaBDFx/yTQu/J+7Bro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/study-NLP-BERT/blob/main/QA_CoQA_Chatbot_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA_CoQA Chatbot model"
      ],
      "metadata": {
        "id": "p3A6u1RME-Jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드"
      ],
      "metadata": {
        "id": "XCZv0i_HQtuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "UeLkcEfBFKjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "FU--OqRGFVpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Tnans2WzFbwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
        "coqa.head()"
      ],
      "metadata": {
        "id": "ZKQ_0mSTJdmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(coqa)"
      ],
      "metadata": {
        "id": "HnxOwvXqKRov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coqa.columns"
      ],
      "metadata": {
        "id": "giwalKAmKcfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del coqa[\"version\"]\n",
        "coqa['data'][0]"
      ],
      "metadata": {
        "id": "VJwCJ4URKm3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coqa['data'][0].keys()"
      ],
      "metadata": {
        "id": "mw1nSFAyKsWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"text\",\"question\",\"answer\"]"
      ],
      "metadata": {
        "id": "Ox9MwoAaN2GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols"
      ],
      "metadata": {
        "id": "Ztzbb23JN2dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "0aPcMSkFQyEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_list = []\n",
        "for index, row in coqa.iterrows():\n",
        "    for i in range(len(row[\"data\"][\"questions\"])):\n",
        "        temp_list = []\n",
        "        temp_list.append(row[\"data\"][\"story\"])\n",
        "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
        "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
        "        comp_list.append(temp_list)\n",
        "\n",
        "new_df = pd.DataFrame(comp_list, columns=cols)\n"
      ],
      "metadata": {
        "id": "TZcZ87vYN3me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv(\"CoQA_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "1glqD4C2Olie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"CoQA_data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "XVPRDrquQRnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of question and answers: \", len(data))"
      ],
      "metadata": {
        "id": "OVApbiyPQRzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링 "
      ],
      "metadata": {
        "id": "Y1x8nkPRQ0ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForQuestionAnswering\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "AjUZR0E0Q2GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "model = TFBertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "id": "ZjZbXYaYRD-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_num = np.random.randint(0,len(data))\n",
        "\n",
        "question = data[\"question\"][random_num]\n",
        "text = data[\"text\"][random_num]"
      ],
      "metadata": {
        "id": "xzFf0HVCRH5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Context: \\n')\n",
        "print(text)\n",
        "print('\\nQuestion: \\n')\n",
        "print(question)\n"
      ],
      "metadata": {
        "id": "xxdvksdBR68c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(question, text, return_tensors=\"tf\")\n",
        "input_ids.keys()"
      ],
      "metadata": {
        "id": "a09IPwrDR7OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "1m6qy-4xSbcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.input_ids[0]"
      ],
      "metadata": {
        "id": "BOBQDnBcSg30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The input has a total of {} tokens.\".format(len(input_ids.input_ids[0])))"
      ],
      "metadata": {
        "id": "52cx7Yn5SwLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.input_ids[0])\n",
        "for token, id in zip(tokens, input_ids.input_ids[0]):\n",
        "    print('{:8}{:8,}'.format(token,id))"
      ],
      "metadata": {
        "id": "cbJpTW2oTKKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_ids)"
      ],
      "metadata": {
        "id": "P3A1ja8aTK_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.start_logits)\n",
        "print('\\n')\n",
        "print(output.end_logits)"
      ],
      "metadata": {
        "id": "AOyy25qYTbXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokens with highest start and end scores\n",
        "answer_start = tf.argmax(tf.cast(output.start_logits, tf.int32), axis=1)\n",
        "answer_end = tf.where(tf.equal(output.end_logits, float(tf.reduce_max(output.end_logits[0]))))[:,-1]"
      ],
      "metadata": {
        "id": "kZW-RmpfT8BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_start, answer_end)"
      ],
      "metadata": {
        "id": "p9FhWYLwrzM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[int(answer_start):int(answer_end)+1]"
      ],
      "metadata": {
        "id": "AAYvgBb01c6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if answer_end >= answer_start:\n",
        "    answer = \" \".join(tokens[int(answer_start):int(answer_end)+1])\n",
        "else:\n",
        "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
        "    \n",
        "print(\"Text:\\n{}\".format(text.capitalize()))\n",
        "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
        "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
      ],
      "metadata": {
        "id": "5kcMojVs1bzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[random_num]"
      ],
      "metadata": {
        "id": "wsNbbM3H2Vtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[int(answer_start)]"
      ],
      "metadata": {
        "id": "Ro_RV5qD2bDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int(answer_start)+1, int(answer_end)+1):\n",
        "    if tokens[i][0:2] == \"##\":\n",
        "        answer += tokens[i][2:]\n",
        "    else:\n",
        "        answer += \" \" + tokens[i]"
      ],
      "metadata": {
        "id": "6Sx_o3s43C6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "id": "XV02Y-Kv3EDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer(question, text):\n",
        "    \n",
        "    #tokenize question and text in ids as a pair\n",
        "    input_ids = tokenizer(question, text, return_tensors=\"tf\")\n",
        "    \n",
        "    #string version of tokenized ids\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.input_ids[0])\n",
        "    \n",
        "    #model output using input_ids and segment_ids\n",
        "    output = model(input_ids)\n",
        "    \n",
        "    #reconstructing the answer\n",
        "    answer_start = tf.argmax(tf.cast(output.start_logits, tf.int32), axis=1)\n",
        "    answer_end = tf.where(tf.equal(output.end_logits, float(tf.reduce_max(output.end_logits[0]))))[:,-1]\n",
        "\n",
        "    if answer_end >= answer_start:\n",
        "        answer = tokens[int(answer_start)]\n",
        "        for i in range(int(answer_start)+1, int(answer_end)+1):\n",
        "            if tokens[i][0:2] == \"##\":\n",
        "                answer += tokens[i][2:]\n",
        "            else:\n",
        "                answer += \" \" + tokens[i]\n",
        "                \n",
        "    if answer.startswith(\"[CLS]\"):\n",
        "        answer = \"Unable to find the answer to your question.\"\n",
        "    \n",
        "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
      ],
      "metadata": {
        "id": "uhuXEkw_3QYe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}