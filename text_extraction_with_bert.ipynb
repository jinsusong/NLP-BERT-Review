{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_extraction_with_bert.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMdB3Jg9jXxFgnoRq1eSiTy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/study-NLP-BERT/blob/main/text_extraction_with_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT (from HuggingFace Transformers) for Text Extraction"
      ],
      "metadata": {
        "id": "J2k741sUaw1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SQuAD(Stanford Question-Answering Dataset)를 사용\n",
        "- SQuAD에서 입력은 질문과 컨텍스트에 대한 단락으로 구성\n",
        "- 목표는 질문에 답하는 단락에서 텍스트의 범위를 찾는 것\n",
        "- 실제 답변 중 하나와 정확히 일치하는 예측의 백분율을 측정하는 \"정확한 일치\" 측정항목을 사용하여 이 데이터에 대한 성능을 평가\n",
        "\n",
        "- BERT 모델을 미세 조정\n",
        "\n",
        "    1. 컨텍스트와 질문을 BERT에 대한 입력으로 제공\n",
        "    2. BERT의 은닉 상태와 같은 차원을 가진 두 벡터 S와 T를 취함.\n",
        "    3. 각 토큰이 응답 범위의 시작과 끝이 될 확률을 계산함.\n",
        "    4. 토큰이 답의 시작이 될 확률은 S와 BERT의 마지막 계층에 있는 토큰 표현 사이의 내적에 의해 주어지며 모든 토큰에 대한 소프트맥스가 뒤따름\n",
        "    5. 토큰이 답의 끝이 될 확률은 벡터 T와 유사하게 계산됨"
      ],
      "metadata": {
        "id": "mV6GSygAa2Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3Jo8N-fmbg-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "\n",
        "max_len = 384\n",
        "configuration = BertConfig()  # default parameters and configuration for BERT"
      ],
      "metadata": {
        "id": "ouDjuIwEbPFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pgMEz9iNbWb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}